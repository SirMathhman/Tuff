// Clone detection module for structural code duplication analysis.
//
// This module implements PMD CPD-inspired clone detection at the IR level,
// operating on the AST rather than tokens. It finds:
// 1. Exact structural clones (identical AST subtrees)
// 2. Parameterized clones (same structure, different values in specific positions)
//
// Algorithm:
// 1. Serialize AST nodes to "IR tokens" (structural representation)
// 2. Use rolling hash to find candidate clone matches
// 3. Verify exact structural matches
// 4. Extend clones to maximal length
// 5. Detect parameterized variants
// 6. Report with line ranges

extern from rt::stdlib use { println, stringLen, stringCharCodeAt, stringSlice };
extern from rt::vec use { vec_new, vec_len, vec_push, vec_get, vec_set };

from util::diagnostics use { warn_at };
from ast use { span_start, span_end };

// ============================================================================
// Configuration
// ============================================================================

let mut __clone_detection_enabled = 0;        // 0=off, 1=warning, 2=error
let mut __clone_min_tokens = 10;              // Minimum IR tokens for a clone
let mut __clone_min_occurrences = 2;          // Minimum occurrences to report
let mut __clone_parameterized_enabled = false; // Enable parameterized detection (very expensive)
let mut __clone_debug = false;

out fn set_clone_detection_options(severity: I32, minTokens: I32, minOccurrences: I32) : Void => {
  __clone_detection_enabled = severity;
  __clone_min_tokens = if (minTokens > 0) minTokens else 10;
  __clone_min_occurrences = if (minOccurrences > 0) minOccurrences else 2;
}

out fn set_clone_detection_debug(enabled: Bool) : Void => {
  __clone_debug = enabled;
}

out fn set_clone_parameterized_enabled(enabled: Bool) : Void => {
  __clone_parameterized_enabled = enabled;
}

// ============================================================================
// IR Token Representation
// ============================================================================
// We serialize AST nodes to a flat sequence of "IR tokens" for comparison.
// Each token represents a structural element (node type, operator, etc.)

class fn IRToken(
  kind: String,   // Node type: "stmt_let", "expr_binary", "op_add", etc.
  spanStart: I32, // Source start position
  spanEnd: I32    // Source end position
) => {}

fn ir_token(kind: String, spanStart: I32, spanEnd: I32) : IRToken =>
  IRToken(kind, spanStart, spanEnd)

// ============================================================================
// AST Serialization to IR Tokens
// ============================================================================

fn serialize_binop(op: BinOp) : String => {
  if (op is OpAdd) { yield "op_add"; }
  if (op is OpSub) { yield "op_sub"; }
  if (op is OpMul) { yield "op_mul"; }
  if (op is OpDiv) { yield "op_div"; }
  if (op is OpEq) { yield "op_eq"; }
  if (op is OpNe) { yield "op_ne"; }
  if (op is OpLt) { yield "op_lt"; }
  if (op is OpLe) { yield "op_le"; }
  if (op is OpGt) { yield "op_gt"; }
  if (op is OpGe) { yield "op_ge"; }
  if (op is OpAnd) { yield "op_and"; }
  if (op is OpOr) { yield "op_or"; }
  "op_unknown"
}

fn serialize_unop(op: UnOp) : String => {
  if (op is OpNot) { yield "op_not"; }
  if (op is OpNeg) { yield "op_neg"; }
  "op_unknown"
}

out fn serialize_expr(e: Expr, tokens: Vec<IRToken>) : Void => {
  let start = span_start(e.span);
  let end = span_end(e.span);

  if (e is EUndefined) {
    vec_push(tokens, ir_token("expr_undefined", start, end));
    yield;
  }

  if (e is EInt) {
    vec_push(tokens, ir_token("expr_int", start, end));
    yield;
  }

  if (e is EFloat) {
    vec_push(tokens, ir_token("expr_float", start, end));
    yield;
  }

  if (e is EBool) {
    vec_push(tokens, ir_token("expr_bool", start, end));
    yield;
  }

  if (e is EString) {
    vec_push(tokens, ir_token("expr_string", start, end));
    yield;
  }

  if (e is EIdent) {
    // Normalize identifiers to just "expr_ident" for structural comparison
    vec_push(tokens, ir_token("expr_ident", start, end));
    yield;
  }

  if (e is EPath) {
    vec_push(tokens, ir_token("expr_path", start, end));
    yield;
  }

  if (e is EUnary) {
    vec_push(tokens, ir_token("expr_unary", start, end));
    vec_push(tokens, ir_token(serialize_unop(e.op), start, end));
    serialize_expr(e.expr, tokens);
    yield;
  }

  if (e is EBinary) {
    vec_push(tokens, ir_token("expr_binary", start, end));
    vec_push(tokens, ir_token(serialize_binop(e.op), start, end));
    serialize_expr(e.left, tokens);
    serialize_expr(e.right, tokens);
    yield;
  }

  if (e is ECall) {
    vec_push(tokens, ir_token("expr_call", start, end));
    serialize_expr(e.callee, tokens);
    let mut i = 0;
    while (i < vec_len(e.args)) {
      serialize_expr(vec_get(e.args, i), tokens);
      i = i + 1;
    }
    vec_push(tokens, ir_token("expr_call_end", start, end));
    yield;
  }

  if (e is EIf) {
    vec_push(tokens, ir_token("expr_if", start, end));
    serialize_expr(e.cond, tokens);
    serialize_expr(e.thenExpr, tokens);
    serialize_expr(e.elseExpr, tokens);
    vec_push(tokens, ir_token("expr_if_end", start, end));
    yield;
  }

  if (e is EBlock) {
    vec_push(tokens, ir_token("expr_block", start, end));
    serialize_stmts(e.body, tokens);
    serialize_expr(e.tail, tokens);
    vec_push(tokens, ir_token("expr_block_end", start, end));
    yield;
  }

  if (e is EVecLit) {
    vec_push(tokens, ir_token("expr_vec", start, end));
    let mut i = 0;
    while (i < vec_len(e.items)) {
      serialize_expr(vec_get(e.items, i), tokens);
      i = i + 1;
    }
    vec_push(tokens, ir_token("expr_vec_end", start, end));
    yield;
  }

  if (e is ETupleLit) {
    vec_push(tokens, ir_token("expr_tuple", start, end));
    let mut i = 0;
    while (i < vec_len(e.items)) {
      serialize_expr(vec_get(e.items, i), tokens);
      i = i + 1;
    }
    vec_push(tokens, ir_token("expr_tuple_end", start, end));
    yield;
  }

  if (e is EIndex) {
    vec_push(tokens, ir_token("expr_index", start, end));
    serialize_expr(e.base, tokens);
    serialize_expr(e.index, tokens);
    yield;
  }

  if (e is ETupleIndex) {
    vec_push(tokens, ir_token("expr_tuple_index", start, end));
    serialize_expr(e.base, tokens);
    yield;
  }

  if (e is EField) {
    vec_push(tokens, ir_token("expr_field", start, end));
    serialize_expr(e.base, tokens);
    yield;
  }

  if (e is EMatch) {
    vec_push(tokens, ir_token("expr_match", start, end));
    serialize_expr(e.scrut, tokens);
    let mut i = 0;
    while (i < vec_len(e.arms)) {
      let arm = vec_get(e.arms, i);
      vec_push(tokens, ir_token("match_arm", span_start(arm.span), span_end(arm.span)));
      serialize_expr(arm.expr, tokens);
      i = i + 1;
    }
    vec_push(tokens, ir_token("expr_match_end", start, end));
    yield;
  }

  if (e is EIsType) {
    vec_push(tokens, ir_token("expr_is_type", start, end));
    serialize_expr(e.expr, tokens);
    yield;
  }

  if (e is ELambda) {
    vec_push(tokens, ir_token("expr_lambda", start, end));
    serialize_expr(e.body, tokens);
    vec_push(tokens, ir_token("expr_lambda_end", start, end));
    yield;
  }

  if (e is EStructLit) {
    vec_push(tokens, ir_token("expr_struct", start, end));
    let mut i = 0;
    while (i < vec_len(e.values)) {
      serialize_expr(vec_get(e.values, i), tokens);
      i = i + 1;
    }
    vec_push(tokens, ir_token("expr_struct_end", start, end));
    yield;
  }

  // Unknown expression type
  vec_push(tokens, ir_token("expr_unknown", start, end));
}

out fn serialize_stmt(s: Stmt, tokens: Vec<IRToken>) : Void => {
  let start = span_start(s.span);
  let end = span_end(s.span);

  if (s is SLet) {
    vec_push(tokens, ir_token(if (s.isMut) "stmt_let_mut" else "stmt_let", start, end));
    serialize_expr(s.init, tokens);
    yield;
  }

  if (s is SAssign) {
    vec_push(tokens, ir_token("stmt_assign", start, end));
    serialize_expr(s.value, tokens);
    yield;
  }

  if (s is SExpr) {
    vec_push(tokens, ir_token("stmt_expr", start, end));
    serialize_expr(s.expr, tokens);
    yield;
  }

  if (s is SYield) {
    vec_push(tokens, ir_token("stmt_yield", start, end));
    serialize_expr(s.expr, tokens);
    yield;
  }

  if (s is SWhile) {
    vec_push(tokens, ir_token("stmt_while", start, end));
    serialize_expr(s.cond, tokens);
    serialize_stmts(s.body, tokens);
    vec_push(tokens, ir_token("stmt_while_end", start, end));
    yield;
  }

  if (s is SIf) {
    vec_push(tokens, ir_token("stmt_if", start, end));
    serialize_expr(s.cond, tokens);
    serialize_stmts(s.thenBody, tokens);
    if (s.hasElse) {
      vec_push(tokens, ir_token("stmt_else", start, end));
      serialize_stmts(s.elseBody, tokens);
    }
    vec_push(tokens, ir_token("stmt_if_end", start, end));
    yield;
  }

  if (s is SIndexAssign) {
    vec_push(tokens, ir_token("stmt_index_assign", start, end));
    serialize_expr(s.base, tokens);
    serialize_expr(s.index, tokens);
    serialize_expr(s.value, tokens);
    yield;
  }

  if (s is SFieldAssign) {
    vec_push(tokens, ir_token("stmt_field_assign", start, end));
    serialize_expr(s.base, tokens);
    serialize_expr(s.value, tokens);
    yield;
  }

  // Unknown statement type
  vec_push(tokens, ir_token("stmt_unknown", start, end));
}

out fn serialize_stmts(stmts: Vec<Stmt>, tokens: Vec<IRToken>) : Void => {
  let mut i = 0;
  while (i < vec_len(stmts)) {
    serialize_stmt(vec_get(stmts, i), tokens);
    i = i + 1;
  }
}

out fn serialize_fn_body(body: Vec<Stmt>, tail: Expr, tokens: Vec<IRToken>) : Void => {
  serialize_stmts(body, tokens);
  serialize_expr(tail, tokens);
}

// ============================================================================
// Clone Detection Data Structures
// ============================================================================

class fn CloneOccurrence(
  startTokenIdx: I32,
  endTokenIdx: I32,
  spanStart: I32,
  spanEnd: I32
) => {}

class fn CloneGroup(
  signature: String,           // Hash/signature of the clone
  tokenCount: I32,             // Number of IR tokens in clone
  occurrences: Vec<CloneOccurrence>
) => {}

// ============================================================================
// Rolling Hash for Clone Detection
// ============================================================================

fn hash_string(s: String) : I32 => {
  let mut hash = 0;
  let mut i = 0;
  while (i < stringLen(s)) {
    hash = hash * 31 + stringCharCodeAt(s, i);
    // Keep hash in reasonable range by wrapping
    if (hash > 100000000) { hash = hash - 100000000; }
    i = i + 1;
  }
  hash
}

fn mod_pos(x0: I32, m: I32) : I32 => {
  // x mod m in [0, m)
  let q = x0 / m;
  let mut r = x0 - q * m;
  if (r < 0) { r = r + m; }
  r
}

fn map_capacity_for(n: I32) : I32 => {
  let mut cap = 16;
  let want = if (n > 0) n * 4 else 16;
  while (cap < want) { cap = cap * 2; }
  cap
}

fn vec_fill_i32(cap: I32, fill: I32) : Vec<I32> => {
  let v = vec_new();
  let mut i = 0;
  while (i < cap) {
    vec_push(v, fill);
    i = i + 1;
  }
  v
}

fn map_find_slot(keys: Vec<I32>, used: Vec<I32>, cap: I32, key: I32) : I32 => {
  let mut idx = mod_pos(key, cap);
  while (vec_get(used, idx) == 1) {
    if (vec_get(keys, idx) == key) { yield idx; }
    idx = idx + 1;
    if (idx >= cap) { idx = 0; }
  }
  idx
}

fn window_equals(tokens: Vec<IRToken>, aStart: I32, bStart: I32, len: I32) : Bool => {
  let mut i = 0;
  while (i < len) {
    if (vec_get(tokens, aStart + i).kind != vec_get(tokens, bStart + i).kind) { yield false; }
    i = i + 1;
  }
  true
}

// Fast clone finding at a fixed window size (minTokens).
// This avoids the previous approach which scanned window sizes minTokens..n/2
// and built huge signature strings.
out fn find_clones_fast(tokens: Vec<IRToken>, minTokens: I32) : Vec<CloneGroup> => {
  let groups = vec_new();
  let tokenLen = vec_len(tokens);
  if (tokenLen < minTokens) { yield groups; }

  let windowSize = minTokens;
  let windowCount = tokenLen - windowSize + 1;
  if (windowCount <= 0) { yield groups; }

  let M = 1000000007;
  let B = 911382;

  let mut powB = 1;
  let mut k = 0;
  while (k < windowSize - 1) {
    powB = mod_pos(powB * B, M);
    k = k + 1;
  }

  // Pre-hash token kinds.
  let kindHashes = vec_new();
  let mut ti = 0;
  while (ti < tokenLen) {
    vec_push(kindHashes, hash_string(vec_get(tokens, ti).kind));
    ti = ti + 1;
  }

  // Map: hash -> group index.
  let cap = map_capacity_for(windowCount);
  let used = vec_fill_i32(cap, 0);
  let keys = vec_fill_i32(cap, 0);
  let vals = vec_fill_i32(cap, -1);

  // Track firstStart per group so we can cheaply confirm equality.
  let firstStarts = vec_new();

  // Initial rolling hash.
  let mut h = 0;
  let mut j = 0;
  while (j < windowSize) {
    h = mod_pos(h * B + vec_get(kindHashes, j), M);
    j = j + 1;
  }

  if (__clone_debug) {
    println("[fluff:clone] tokens=" + tokenLen + " windowSize=" + windowSize + " windows=" + windowCount + " mapCap=" + cap);
  }

  let mut i = 0;
  while (i < windowCount) {
    let key = h;
    let slot = map_find_slot(keys, used, cap, key);
    if (vec_get(used, slot) == 0) {
      // New group.
      vec_set(used, slot, 1);
      vec_set(keys, slot, key);
      let occs = vec_new();
      let startToken = vec_get(tokens, i);
      let endToken = vec_get(tokens, i + windowSize - 1);
      vec_push(occs, CloneOccurrence(i, i + windowSize, startToken.spanStart, endToken.spanEnd));

      let sig = "h=" + ("" + key);
      let newIdx = vec_len(groups);
      vec_push(groups, CloneGroup(sig, windowSize, occs));
      vec_push(firstStarts, i);
      vec_set(vals, slot, newIdx);
    } else {
      let gIdx = vec_get(vals, slot);
      // Very unlikely: hash collision. If it happens, we conservatively ignore.
      if (gIdx >= 0) {
        let firstStart = vec_get(firstStarts, gIdx);
        if (window_equals(tokens, firstStart, i, windowSize)) {
          let g = vec_get(groups, gIdx);
          let nOcc = vec_len(g.occurrences);
          let startToken = vec_get(tokens, i);
          let endToken = vec_get(tokens, i + windowSize - 1);
          let occ = CloneOccurrence(i, i + windowSize, startToken.spanStart, endToken.spanEnd);

          // Avoid counting overlapping windows (keeps counts sane and runtime bounded).
          if (nOcc == 0) {
            vec_push(g.occurrences, occ);
          } else {
            let last = vec_get(g.occurrences, nOcc - 1);
            if (occ.startTokenIdx >= last.endTokenIdx) {
              vec_push(g.occurrences, occ);
            }
          }
        }
      }
    }

    // Roll forward.
    if (i + 1 < windowCount) {
      let outVal = vec_get(kindHashes, i);
      let inVal = vec_get(kindHashes, i + windowSize);
      let mut t = mod_pos(h - mod_pos(outVal * powB, M), M);
      t = mod_pos(t * B + inVal, M);
      h = t;
    }

    i = i + 1;
  }

  // Filter groups by occurrence count.
  let filtered = vec_new();
  let mut gi = 0;
  while (gi < vec_len(groups)) {
    let g = vec_get(groups, gi);
    if (vec_len(g.occurrences) >= __clone_min_occurrences) {
      vec_push(filtered, g);
    }
    gi = gi + 1;
  }

  if (__clone_debug) {
    println("[fluff:clone] groups=" + vec_len(groups) + " reported=" + vec_len(filtered));
  }

  filtered
}

fn compute_sequence_signature(tokens: Vec<IRToken>, start: I32, len: I32) : String => {
  let mut sig = "";
  let mut i = 0;
  while (i < len && (start + i) < vec_len(tokens)) {
    let t = vec_get(tokens, start + i);
    sig = sig + t.kind + ";";
    i = i + 1;
  }
  sig
}

// ============================================================================
// Clone Finding Algorithm
// ============================================================================

fn find_clone_group_by_signature(groups: Vec<CloneGroup>, sig: String) : I32 => {
  let mut i = 0;
  while (i < vec_len(groups)) {
    let g = vec_get(groups, i);
    if (g.signature == sig) { yield i; }
    i = i + 1;
  }
  -1
}

fn occurrences_overlap(o1: CloneOccurrence, o2: CloneOccurrence) : Bool => {
  // Check if two occurrences overlap in source position
  if (o1.spanEnd <= o2.spanStart) { yield false; }
  if (o2.spanEnd <= o1.spanStart) { yield false; }
  true
}

fn group_has_overlapping_occurrence(group: CloneGroup, occ: CloneOccurrence) : Bool => {
  let mut i = 0;
  while (i < vec_len(group.occurrences)) {
    let existing = vec_get(group.occurrences, i);
    if (occurrences_overlap(existing, occ)) { yield true; }
    i = i + 1;
  }
  false
}

out fn find_clones(tokens: Vec<IRToken>, minTokens: I32) : Vec<CloneGroup> => {
  let groups = vec_new();
  let tokenLen = vec_len(tokens);

  if (tokenLen < minTokens) { yield groups; }

  // Sliding window: for each window of size minTokens..tokenLen/2
  let maxWindowSize = tokenLen / 2;
  let mut windowSize = minTokens;

  while (windowSize <= maxWindowSize) {
    // Scan all positions for this window size
    let mut i = 0;
    while (i + windowSize <= tokenLen) {
      let sig = compute_sequence_signature(tokens, i, windowSize);

      // Get span info for this window
      let startToken = vec_get(tokens, i);
      let endToken = vec_get(tokens, i + windowSize - 1);
      let occ = CloneOccurrence(
        i,
        i + windowSize,
        startToken.spanStart,
        endToken.spanEnd
      );

      // Find or create clone group
      let groupIdx = find_clone_group_by_signature(groups, sig);

      if (groupIdx >= 0) {
        // Add to existing group if not overlapping
        let existingGroup = vec_get(groups, groupIdx);
        if (!group_has_overlapping_occurrence(existingGroup, occ)) {
          vec_push(existingGroup.occurrences, occ);
        }
      } else {
        // Create new group
        let newOccs = vec_new();
        vec_push(newOccs, occ);
        vec_push(groups, CloneGroup(sig, windowSize, newOccs));
      }

      i = i + 1;
    }

    windowSize = windowSize + 1;
  }

  // Filter to only groups with multiple occurrences
  let filtered = vec_new();
  let mut gi = 0;
  while (gi < vec_len(groups)) {
    let g = vec_get(groups, gi);
    if (vec_len(g.occurrences) >= __clone_min_occurrences) {
      vec_push(filtered, g);
    }
    gi = gi + 1;
  }

  filtered
}

// ============================================================================
// Maximal Clone Extension
// ============================================================================
// Given a clone, extend it in both directions while tokens still match

out fn extend_clone_maximal(tokens: Vec<IRToken>, groups: Vec<CloneGroup>) : Vec<CloneGroup> => {
  // For each group, try to extend all occurrences together
  let extended = vec_new();
  let mut gi = 0;

  while (gi < vec_len(groups)) {
    let group = vec_get(groups, gi);

    if (vec_len(group.occurrences) < 2) {
      gi = gi + 1;
      continue;
    }

    // Try to extend forward
    let mut canExtendForward = true;
    while (canExtendForward) {
      let firstOcc = vec_get(group.occurrences, 0);
      let nextIdx = firstOcc.endTokenIdx;

      if (nextIdx >= vec_len(tokens)) {
        canExtendForward = false;
        continue;
      }

      let expectedKind = vec_get(tokens, nextIdx).kind;

      // Check all other occurrences have same next token
      let mut allMatch = true;
      let mut oi = 1;
      while (oi < vec_len(group.occurrences)) {
        let occ = vec_get(group.occurrences, oi);
        if (occ.endTokenIdx >= vec_len(tokens)) {
          allMatch = false;
          break;
        }
        let actualKind = vec_get(tokens, occ.endTokenIdx).kind;
        if (actualKind != expectedKind) {
          allMatch = false;
          break;
        }
        oi = oi + 1;
      }

      if (allMatch) {
        // Extend all occurrences forward
        let mut oi2 = 0;
        while (oi2 < vec_len(group.occurrences)) {
          let occ = vec_get(group.occurrences, oi2);
          let newEnd = occ.endTokenIdx + 1;
          let newSpanEnd = vec_get(tokens, newEnd - 1).spanEnd;
          vec_set(group.occurrences, oi2, CloneOccurrence(
            occ.startTokenIdx,
            newEnd,
            occ.spanStart,
            newSpanEnd
          ));
          oi2 = oi2 + 1;
        }
      } else {
        canExtendForward = false;
      }
    }

    // Update token count
    let firstOcc = vec_get(group.occurrences, 0);
    let newTokenCount = firstOcc.endTokenIdx - firstOcc.startTokenIdx;

    vec_push(extended, CloneGroup(
      group.signature,
      newTokenCount,
      group.occurrences
    ));

    gi = gi + 1;
  }

  extended
}

// ============================================================================
// Parameterized Clone Detection
// ============================================================================
// Compare two sequences and find positions where they differ

class fn ParameterPosition(
  tokenOffset: I32,    // Offset within the clone where parameter appears
  variations: Vec<String>  // The different values at this position
) => {}

class fn ParameterizedClone(
  baseSignature: String,
  tokenCount: I32,
  parameters: Vec<ParameterPosition>,
  occurrences: Vec<CloneOccurrence>
) => {}

fn tokens_differ_only_in_values(tokens: Vec<IRToken>, occ1: CloneOccurrence, occ2: CloneOccurrence) : Vec<I32> => {
  // Compare two occurrences and return positions where they structurally differ
  let diffPositions = vec_new();

  let len1 = occ1.endTokenIdx - occ1.startTokenIdx;
  let len2 = occ2.endTokenIdx - occ2.startTokenIdx;

  if (len1 != len2) { yield diffPositions; }

  let mut i = 0;
  while (i < len1) {
    let t1 = vec_get(tokens, occ1.startTokenIdx + i);
    let t2 = vec_get(tokens, occ2.startTokenIdx + i);

    // Check if kinds match (structure) - if not, it's a structural difference
    if (t1.kind != t2.kind) {
      // Only allow parameterization for leaf nodes (identifiers, literals)
      if (t1.kind == "expr_ident" || t1.kind == "expr_int" ||
          t1.kind == "expr_string" || t1.kind == "expr_bool" ||
          t1.kind == "expr_float") {
        // And corresponding types must match
        if (t1.kind == t2.kind) {
          vec_push(diffPositions, i);
        } else {
          // Structural mismatch - not parameterizable
          yield vec_new();
        }
      } else {
        // Non-leaf difference - not parameterizable
        yield vec_new();
      }
    }

    i = i + 1;
  }

  diffPositions
}

out fn find_parameterized_clones(tokens: Vec<IRToken>, exactClones: Vec<CloneGroup>, minTokens: I32) : Vec<ParameterizedClone> => {
  if (!__clone_parameterized_enabled) { yield vec_new(); }

  let paramClones = vec_new();

  // For sequences that are "almost" clones, try to parameterize
  // This is a simplified approach: look for sequences with same length
  // that differ in only a few leaf positions

  let tokenLen = vec_len(tokens);
  let maxWindowSize = tokenLen / 2;
  let mut windowSize = minTokens;

  while (windowSize <= maxWindowSize) {
    // Group sequences by "structure signature" (ignoring leaf values)
    let structureGroups = vec_new();

    let mut i = 0;
    while (i + windowSize <= tokenLen) {
      // Create structural signature (replace leaf nodes with placeholders)
      let mut structSig = "";
      let mut j = 0;
      while (j < windowSize) {
        let t = vec_get(tokens, i + j);
        let kind = t.kind;
        // Normalize leaf nodes to placeholders
        let normKind = if (kind == "expr_ident") "PARAM"
          else if (kind == "expr_int") "PARAM"
          else if (kind == "expr_string") "PARAM"
          else if (kind == "expr_float") "PARAM"
          else if (kind == "expr_bool") "PARAM"
          else kind;
        structSig = structSig + normKind + ";";
        j = j + 1;
      }

      let startToken = vec_get(tokens, i);
      let endToken = vec_get(tokens, i + windowSize - 1);
      let occ = CloneOccurrence(
        i,
        i + windowSize,
        startToken.spanStart,
        endToken.spanEnd
      );

      // Find or create group for this structural signature
      let groupIdx = find_clone_group_by_signature(structureGroups, structSig);
      if (groupIdx >= 0) {
        let existingGroup = vec_get(structureGroups, groupIdx);
        if (!group_has_overlapping_occurrence(existingGroup, occ)) {
          vec_push(existingGroup.occurrences, occ);
        }
      } else {
        let newOccs = vec_new();
        vec_push(newOccs, occ);
        vec_push(structureGroups, CloneGroup(structSig, windowSize, newOccs));
      }

      i = i + 1;
    }

    // Filter to groups with 2+ occurrences that aren't already exact clones
    let mut gi = 0;
    while (gi < vec_len(structureGroups)) {
      let g = vec_get(structureGroups, gi);
      if (vec_len(g.occurrences) >= __clone_min_occurrences) {
        // Check if this is already an exact clone (skip if so)
        let firstOcc = vec_get(g.occurrences, 0);
        let exactSig = compute_sequence_signature(tokens, firstOcc.startTokenIdx, g.tokenCount);

        let isExact = find_clone_group_by_signature(exactClones, exactSig) >= 0;

        if (!isExact) {
          // This is a parameterized clone
          let params = vec_new();
          vec_push(paramClones, ParameterizedClone(
            g.signature,
            g.tokenCount,
            params,
            g.occurrences
          ));
        }
      }
      gi = gi + 1;
    }

    windowSize = windowSize + 1;
  }

  paramClones
}

// ============================================================================
// Reporting
// ============================================================================

fn emit_clone_warning(src: String, severity: I32, pos: I32, msg: String) : Void => {
  if (severity == 1) { warn_at(src, pos, msg); yield; }
  if (severity == 2) { warn_at(src, pos, msg); yield; } // Could use error_at
}

out fn report_clones(src: String, exactClones: Vec<CloneGroup>, paramClones: Vec<ParameterizedClone>) : Void => {
  if (__clone_detection_enabled == 0) { yield; }

  // Report exact clones
  let mut gi = 0;
  while (gi < vec_len(exactClones)) {
    let g = vec_get(exactClones, gi);
    let occCount = vec_len(g.occurrences);

    if (occCount >= __clone_min_occurrences && g.tokenCount >= __clone_min_tokens) {
      let firstOcc = vec_get(g.occurrences, 0);
      let msg = "code clone detected: " + ("" + g.tokenCount) + " IR tokens duplicated " +
                ("" + occCount) + " times; consider extracting to a function";
      emit_clone_warning(src, __clone_detection_enabled, firstOcc.spanStart, msg);
    }

    gi = gi + 1;
  }

  // Report parameterized clones
  let mut pi = 0;
  while (pi < vec_len(paramClones)) {
    let p = vec_get(paramClones, pi);
    let occCount = vec_len(p.occurrences);

    if (occCount >= __clone_min_occurrences && p.tokenCount >= __clone_min_tokens) {
      let firstOcc = vec_get(p.occurrences, 0);
      let msg = "parameterized clone detected: " + ("" + p.tokenCount) +
                " IR tokens with variations, appears " + ("" + occCount) +
                " times; consider extracting to a parameterized function";
      emit_clone_warning(src, __clone_detection_enabled, firstOcc.spanStart, msg);
    }

    pi = pi + 1;
  }
}

// ============================================================================
// Main Entry Point
// ============================================================================

out fn analyze_fn_for_clones(src: String, fnName: String, body: Vec<Stmt>, tail: Expr) : Void => {
  if (__clone_detection_enabled == 0) { yield; }

  // Serialize function body to IR tokens
  let tokens = vec_new();
  serialize_fn_body(body, tail, tokens);

  // Skip small functions
  if (vec_len(tokens) < __clone_min_tokens * 2) { yield; }

  // Find exact clones (fast fixed-window implementation)
  let exactClones = find_clones_fast(tokens, __clone_min_tokens);
  report_clones(src, exactClones, vec_new());
}

out fn analyze_program_for_clones(src: String, decls: Vec<Decl>) : Void => {
  if (__clone_detection_enabled == 0) { yield; }

  // Serialize entire program to IR tokens for cross-function clone detection
  let tokens = vec_new();

  let mut i = 0;
  while (i < vec_len(decls)) {
    let d = vec_get(decls, i);

    if (d is DFn) {
      serialize_fn_body(d.body, d.tail, tokens);
    }

    if (d is DClassFn) {
      serialize_fn_body(d.body, d.tail, tokens);
    }

    i = i + 1;
  }

  // Skip small programs
  if (vec_len(tokens) < __clone_min_tokens * 2) { yield; }

  // Find exact clones (fast fixed-window implementation)
  let exactClones = find_clones_fast(tokens, __clone_min_tokens);
  report_clones(src, exactClones, vec_new());
}
